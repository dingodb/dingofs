# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, DataCanvas
# This file is distributed under the same license as the DingoFS package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: DingoFS\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-05-30 10:29+0800\n"
"PO-Revision-Date: 2025-06-06 15:36+0800\n"
"Last-Translator: \n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"
"X-Generator: Poedit 3.6\n"

#: ../../source/architecture/client-architecture.md:1
#: bdf7a2c40d41451b8b8e69f6157a3053
msgid "Client Architecture"
msgstr "Client 架构"

#: ../../source/architecture/client-architecture.md:2
#: d45edd340b7e4e6a9daf42961a3d667b
msgid "1.Summary"
msgstr "1.概要"

#: ../../source/architecture/client-architecture.md:3
#: aa068a3b662b4650a8e495535b33444c
msgid ""
"As a DingoFS client, the client uses the rpc interface to send requests to the "
"back-end metadata cluster and data cluster, and calls the back-end interface "
"to realize the corresponding functions. DingoFS client supports S3 compatible "
"object storage."
msgstr ""
"DingoFS Client 作为 DingoFS 的客户端，使用 rpc 接口向后端元数据集群和数据集群发"
"送请求，并调用后端接口实现相应功能。DingoFS 客户端支持与 S3 兼容的对象存储。"

#: ../../source/architecture/client-architecture.md:5
#: 16f2f784272a4aff8eb42ca90661f667
msgid "2.Functions"
msgstr "2.功能介绍"

#: ../../source/architecture/client-architecture.md:6
#: a48e6ef3f63c4d1e87b95f9732b140fb
msgid "Provide standard POSIX file system interface"
msgstr "提供标准POSIX文件系统接口"

#: ../../source/architecture/client-architecture.md:7
#: 7be303dd9d17474097b998faf9f2d3cf
msgid ""
"DingoFS client supports fuse userland file system by interfacing with "
"libfuse's lowlevel fuse api to realize standard POSIX file system interface."
msgstr ""
"DingoFS client通过对接libfuse 的 lowlevel fuse api，支持fuse用户态文件系统，实"
"现标准POSIX文件系统接口。"

#: ../../source/architecture/client-architecture.md:9
#: 13e354c9abba48d585334a3f3329ddde
msgid "Support S3 storage engine to store data and cache"
msgstr "支持S3存储引擎存储数据与缓存"

#: ../../source/architecture/client-architecture.md:10
#: 4860ee8ec0124ca6bd0df404578116b8
msgid ""
"DingoFS client supports to convert file system data into object storage "
"through certain format, and save the file data in S3 storage engine through S3 "
"interface compatible client (using S3 C++ sdk). The DingoFS client supports "
"two levels of data caching, memory and disk caching, which accelerates the "
"performance of reading and writing S3 data."
msgstr ""
"DingoFS client 支持将文件系统数据，通过一定的格式，转换称为对象存储中的对象，并"
"通过S3接口兼容的客户端（使用S3 C++ sdk）将文件数据保存在S3存储引擎中。 DingoFS "
"client支持内存与磁盘缓存的二级的数据缓存，从而加速S3数据的读写性能。"

#: ../../source/architecture/client-architecture.md:13
#: 1c486f63b1594455bb69cbdb384c0d0b
msgid "Metadata Fetching and Caching"
msgstr "元数据获取和缓存"

#: ../../source/architecture/client-architecture.md:14
#: 114706bca02f471fae794ee2ef1daf41
msgid ""
"The DingoFS client stores file system metadata in the DingoFS metadata "
"cluster. The DingoFS client supports caching metadata on the client side to "
"provide faster metadata access. The cached metadata information includes."
msgstr ""
"DingoFS client 将文件系统元数据存储于DingoFS 元数据集群，DingoFS client支持将元"
"数据缓存在client端，从而提供更快速地元数据访问。其缓存的元数据信息有。"

#: ../../source/architecture/client-architecture.md:15
#: 2349a1252fef4bd6918b6ac390478c99
msgid "File system global information, i.e. FsInfo."
msgstr "文件系统全局信息，即FsInfo。"

#: ../../source/architecture/client-architecture.md:16
#: 93b3bf097f294539883abee579e71a67
msgid ""
"FsInfo. Metadata for each file and directory, including dentry information and "
"inode information."
msgstr "各文件和目录的元数据，包括dentry信息和inode信息两大部分。"

#: ../../source/architecture/client-architecture.md:17
#: f6b1b405fa9c49e997c935e9fd13d83f
msgid ""
"The metadata of each file and directory is distributed in Copyset and "
"Partition information, which is cached by the DingoFS client to request "
"metadata operations from the corresponding Copyset and Partition."
msgstr ""
"各文件和目录的元数据的分布于的Copyset与Partition信息，DingoFS client缓存这些信"
"息，从而向对应的Copyset与Partition请求元数据操作。"

#: ../../source/architecture/client-architecture.md:18
#: 2ef9539cbf7e490f822623ab96fb1901
msgid ""
"Topology information of metadata clusters, DingoFS client needs to know the "
"topology information of metadata clusters such as ip, port, etc., so as to "
"know which ip, port to send rpc to."
msgstr ""
"元数据集群的拓扑信息，DingoFS client需要知道元数据集群的ip、端口等拓扑信息，从"
"而知道向哪个ip、端口发送rpc。"

#: ../../source/architecture/client-architecture.md:20
#: 35cd6608fc1e42a5b35ddc7595ce4af5
msgid "Exception Handling and Retries for Metadata Requests"
msgstr "元数据请求的异常处理和重试"

#: ../../source/architecture/client-architecture.md:21
#: b897bc59fd2342b3bbd0c6184add2dc6
msgid ""
"The DingoFS mds and DingoFS metaserver clusters, which enable highly available "
"deployments, where the"
msgstr "DingoFS mds 和 DingoFS metaserver集群，实现了高可用部署，其中"

#: ../../source/architecture/client-architecture.md:22
#: e0952713c0d74c608cf8ed5077c91740
msgid ""
"DingoFS mds has only one mds providing service at the same time, and other mds "
"nodes are listening through etcd. When the main mds has an exception, the "
"backup mds can replace the leader at any time, and at this time, the DingoFS "
"client needs to look for the main mds and retry the rpc request to deal with "
"the situation."
msgstr ""
"DingoFS mds 同一时刻只有一个mds提供服务，其他mds节点通过etcd监听，当主mds发生异"
"常时，备mds能够随时替代成为leader，此时需要DingoFS client寻找主mds和重试rpc请求"
"以处理该种情况。"

#: ../../source/architecture/client-architecture.md:23
#: 3d38ca1cb0f845d4b3323da6908b7979
msgid ""
"The DingoFS metaserver cluster is a mutiraft cluster that provides services to "
"DingoFS clients, and there are similar scenarios such as leader switching, "
"which requires the DingoFS client to GetLeader and retry rpc requests after "
"switching leaders."
msgstr ""
"DingoFS metaserver集群，是以mutiraft集群的方式，对DingoFS client提供服务的，也"
"会存在类似的leader切换等场景，此时也需要DingoFS client 去GetLeader以及在切换"
"leader后重试rpc请求。"

#: ../../source/architecture/client-architecture.md:24
#: c7b3441b03a44da09003e0d6833c8660
msgid ""
"In addition, the DingoFS client's communication with the above components may "
"also result in rpc timeouts due to network busyness, etc., which also requires "
"the DingoFS client to retry the request."
msgstr ""
"除此之外，DingoFS client与上述组件的通信，也会因为网络繁忙等原因，造成rpc的超时"
"等问题，那么同样需要DingoFS client 实现请求的重试。"

#: ../../source/architecture/client-architecture.md:26
#: 638f4f4cabd8413f9742f42933b8394a
msgid "3.Architecture"
msgstr "3.架构"

#: ../../source/architecture/client-architecture.md:28
#: 0947089b2764406fa5f20d583217d11a
msgid "The DingoFS client consists of several main modules:"
msgstr "DingoFS client包含几个主要模块："

#: ../../source/architecture/client-architecture.md:30
#: 1bc4b35d6a5c4ed39268cbdb9832c13c
msgid ""
"libfuse, which interfaces with its lowlevel fuse api to support the fuse "
"userland filesystem;"
msgstr "libfuse，对接了其lowlevel fuse api，支持fuse用户态文件系统；"

#: ../../source/architecture/client-architecture.md:31
#: 7dc1ba4485d14a3780da9c8a01b765e1
msgid ""
"metadata cache, including fsinfo, inode cache, dentry cache, to realize the "
"cache of metadata;"
msgstr "元数据cache，包含fsinfo, inode cache, dentry cache, 实现对元数据的缓存；"

#: ../../source/architecture/client-architecture.md:32
#: 57fa270434aa443da778e0d8bcbc7c21
msgid ""
"meta rpc client, mainly interfacing with metadata cluster, realizing meta op "
"sending, timeout retry and other functions;"
msgstr ""
"meta rpc client， 主要对接元数据集群，实现meta op的发送，超时重试等功能；"

#: ../../source/architecture/client-architecture.md:33
#: 932905f560d846f39ed5626002be3845
msgid "S3 client, through the interface to S3, the data will be stored in S3;"
msgstr "S3 client， 通过对接S3接口，将数据存储在S3中；"

#: ../../source/architecture/client-architecture.md:34
#: 3cb455a2cd39421d93eb9178d5eb51a7
msgid ""
"S3 data cache, which is the memory cache layer of the S3 datastore, serves as "
"a data cache to accelerate the read and write performance of S3 data;"
msgstr ""
"S3 data cache， 这是S3数据存储的内存缓存层，作为数据缓存，加速S3数据的读写性"
"能；"

#: ../../source/architecture/client-architecture.md:35
#: 411b23ea198d47fe833b3e6a31e2cc63
msgid ""
"S3 disk cache, which is the local persistent cache of the S3 data store, "
"temporarily caches the reads and writes to the S3 data on the local disk "
"through the disk cache and later uploads them to S3 asynchronously, thus "
"effectively reducing the latency and providing throughput;"
msgstr ""
"S3 disk cache，这是S3数据存储的本地持久化缓存，通过磁盘缓存，将对S3数据的读写暂"
"时缓存在本地磁盘上，稍后在异步上传到S3，从而有效降低时延，提供吞吐；"

#: ../../source/architecture/client-architecture.md:37
#: 6f70da719d104040a7a5752dc60b809e
msgid "4.IO Flow"
msgstr "4.IO流程"

#: ../../source/architecture/client-architecture.md:38
#: a41e6f0f301d4a90a151ed81a31dc258
msgid ""
"The IO flow of DingoFS Client is divided into two major parts, which are Meta "
"Data Meta IO flow and Data Data IO flow."
msgstr ""
"DingoFS Client的IO流程分为两大部分，分别是元数据Meta IO流和数据Data IO流。"

#: ../../source/architecture/client-architecture.md:40
#: 7a0ff50019ee479caf1a01c926dd84e2
msgid "Meta IO Flow"
msgstr "Meta IO 流"

#: ../../source/architecture/client-architecture.md:41
#: 53c8220639d2499ab5b77caccfa5d094
msgid ""
"![](../../images/mknod_flow.png) The Meta IO flow for DingoFS, in the case of "
"MkNod, consists of the following process:"
msgstr ""
"![](../../images/mknod_flow.png) DingoFS 的元数据IO流，以MkNod为例，包含如下过"
"程："

#: ../../source/architecture/client-architecture.md:43
#: 1b0b846785144e4fbe727f64c6b69167
msgid ""
"The user invokes the file system MkNod interface, which passes through the "
"user-state file system fuse low level api and reaches the DingoFS client "
"interface;"
msgstr ""
"用户调用文件系统MkNod接口，经过用户态文件系统fuse low level api，到达DingoFS "
"client接口；"

#: ../../source/architecture/client-architecture.md:44
#: c5f56a855eb54d3785c4f7a7103186d5
msgid ""
"MkNod needs to perform two operations, CreateInode and CreateDentry, the "
"CreateInode process first needs to decide the partition to create the Inode, "
"usually the topo information and partition information are cached in the "
"DingoFS client, if there is no such information in the cache, then the DingoFS "
"client will not be able to create the Inode, and the DingoFS client will not "
"be able to create the partition. If there is no such information in the cache, "
"the DingoFS client will first go to the mds to get the information;"
msgstr ""
"MkNod需要执行两步操作，分别是CreateInode和CreateDentry。CreateInode过程首先需要"
"决定创建Inode的partition。通常情况下，topo信息和partition信息缓存在DingoFS "
"client端，如果缓存中没有这些信息，那么DingoFS Client首先会去mds获取这些信息；"

#: ../../source/architecture/client-architecture.md:45
#: fd664442a7d14bcfb347b3ad07428ab5
msgid ""
"Based on the partition information in the cache, the DingoFS client decides to "
"create the Inode's partiton according to a certain policy;"
msgstr ""
"DingoFS client根据缓存中的partition信息，根据一定的策略，决定创建Inode的"
"partiton；"

#: ../../source/architecture/client-architecture.md:46
#: 8d9d579096fd475a9a19659e2765ce7e
msgid ""
"Based on the topo information and partiton information in the cache or "
"obtained, find the copyset where the Inode needs to be created;"
msgstr ""
"根据缓存中或者获取到的topo信息以及partiton信息，找到需要创建Inode的copyset；"

#: ../../source/architecture/client-architecture.md:47
#: cdd971379492461dbdadd26c9f578770
msgid ""
"If the leader information is cached in the copyset, then the CreateInode rpc "
"request can be sent directly to the corresponding metaserver, otherwise, it is "
"necessary to obtain the leader information from any metaserver in the copyset;"
msgstr ""
"如果该copyset中缓存了leader信息，那么就可以直接发送CreateInode的rpc请求到对应的"
"metaserver，否则，此时还需要向copyset中任一metaserver获取leader信息；"

#: ../../source/architecture/client-architecture.md:48
#: f9cf24da1f5542b8b04ec85504734719
msgid ""
"After calling CreateInode's rpc to create the Inode, the next step is to "
"CreateDentry;"
msgstr "调用CreateInode的rpc创建完Inode后，接下来就要CreateDentry了；"

#: ../../source/architecture/client-architecture.md:49
#: 7b19ccde32774b91ab9747d85b45ebf1
msgid ""
"Similarly, the Create Dentry process first needs to decide the partiton for "
"creating the Dentry according to a certain strategy;"
msgstr ""
"同样的，Create Dentry过程，首先也需要根据一定的策略，决定创建Dentry的partiton；"

#: ../../source/architecture/client-architecture.md:50
#: aef6fd768d864f0d92081e16a6a3c3b9
msgid ""
"After that, the Create Dentry process finds the copyset where the Dentry is to "
"be created based on the topo information and partiton information in the cache "
"or obtained;"
msgstr ""
"之后，Create Dentry过程根据缓存中或者获取到的topo信息以及partiton信息，找到需要"
"创建Dentry的copyset；"

#: ../../source/architecture/client-architecture.md:51
#: e29f86ac8d0241adb18a5b3d62813310
msgid ""
"If the leader information is cached in the copyset, then the CreateDentry rpc "
"request can be sent directly to the corresponding metaserver; otherwise, it "
"needs to get the leader information from any metaserver in the copyset;"
msgstr ""
"如果该copyset中缓存了leader信息，那么就可以直接发送CreateDentry的rpc请求到对应"
"的metaserver，否则还需要向copyset中任一metaserver获取leader信息；"

#: ../../source/architecture/client-architecture.md:52
#: a2984da6c6e64150b00eba0bbc55711a
msgid "After CreateDentry is completed, the function of MkNod is finished."
msgstr "创建Dentry完成后，即完成了MkNod的功能。"

#: ../../source/architecture/client-architecture.md:54
#: 9a02903425f94202bd67ab6fee3043bd
msgid "Data IO stream"
msgstr "Data IO 流"

#: ../../source/architecture/client-architecture.md:55
#: 9a3a0f5859c84c89a090c49ea101e29a
msgid ""
"![](../../images/s3_dataio_flow.png) The Data IO flow stored to S3 consists of "
"the following process:"
msgstr ""
"![](../../images/s3_dataio_flow.png) 数据存储到S3的Data IO流包括以下几个进程："

#: ../../source/architecture/client-architecture.md:57
#: 4f16fb33311c4b43b8d0eef503520689
msgid ""
"The user invokes the file system write interface, which passes through the "
"userland file system fuse low level api and reaches the DingoFS client "
"interface;"
msgstr ""
"用户调用文件系统write接口，经过用户态文件系统fuse low level api，到达DingoFS "
"client接口；"

#: ../../source/architecture/client-architecture.md:58
#: 28c15624f2694d5789ad7bb32881737b
msgid "The DingoFS client's write interface writes data to the Data Cache first;"
msgstr "DingoFS client 的write接口会先将数据写入Data Cache中；"

#: ../../source/architecture/client-architecture.md:59
#: be008d7994ef4f29935a4109c788cf58
msgid ""
"When the DataCache is full or the periodic refresh time arrives, DingoFS "
"client will start the data sync process;"
msgstr ""
"当DataCache数据满或者周期性的刷新时候到了的时候，DingoFS client将开始数据的Sync"
"过程；"

#: ../../source/architecture/client-architecture.md:60
#: e5dd3c96b4ee4ab6bc8972ff37bdecfe
msgid ""
"DingoFS client will first write the data to S3 (if there is a disk cache, it "
"will write the data to the disk cache first, and then asynchronously write the "
"data to S3 later);; After the data is written to S3, DingoFS client will write "
"the data to S3 asynchronously, and then write the data to S3 asynchronously."
msgstr ""
"DingoFS client首先会将数据写入S3，（如果有disk cache，会先将数据写入disk "
"cache，稍后再异步将数据写入S3）。"

#: ../../source/architecture/client-architecture.md:61
#: e31469e6cf46461594ca0cc656390fa8
msgid ""
"After the data is written to S3, the DingoFS client will record the meta "
"information of the data written to S3 and organize it into S3ChunkInfo;"
msgstr ""
"数据写入S3之后，DingoFS client会记录写入S3的数据的元信息，组织成S3ChunkInfo；"

#: ../../source/architecture/client-architecture.md:62
#: 21e63effe3034b9c836bdf041c1bf36d
msgid ""
"If the DingoFS client does not cache the Inode information at this time, then "
"it will follow the metadata flow in the previous section to get the Inode from "
"the metaserver."
msgstr ""
"如果此时DingoFS client 没有缓存Inode信息，那么将会走前一节流程中的元数据流从"
"metaserver获取Inode。"

#: ../../source/architecture/client-architecture.md:65
#: 97e4bb54a71e4e829af5d15e21d12571
msgid ""
"After getting the Inode, DingoFS client will add S3ChunkInfo information to "
"the Inode;"
msgstr "得到Inode后，DingoFS client会将S3ChunkInfo信息添加到Inode中；"

#: ../../source/architecture/client-architecture.md:66
#: 91ac2070acd54ed685405e6c6cafb3aa
msgid ""
"After completing the local Inode update, DingoFS client will call "
"AppendS3ChunkInfo RPC interface to incrementally update the Inode information "
"on the metaserver side;"
msgstr ""
"完成本地Inode更新之后，DingoFS client 将会调用AppendS3ChunkInfo RPC接口增量更新"
"metaserver端的Inode信息；"

#: ../../source/architecture/client-architecture.md:68
#: d5a75cca6d8f4d9088eb797731f4af2f
msgid "5.Exception Handling"
msgstr "5.异常处理"

#: ../../source/architecture/client-architecture.md:69
#: 1349583254454d0aae845bdfc544cb8b
msgid ""
"The exception handling of the DingoFS client mainly refers to idempotent "
"request returns for various exceptions of the metadata cluster. It mainly "
"involves retrying the rpc requests to the metadata cluster mds and metaserver, "
"which involves including the following functions:"
msgstr ""
"DingoFS client 的异常处理，主要指的是对元数据集群的各种异常，进行幂等的请求返"
"回。主要涉及到对元数据集群mds和metaserver的rpc请求的重试，涉及包括如下功能："

#: ../../source/architecture/client-architecture.md:70
#: 6a7b0ff2bd98456f81db4c7b458ab9bb
msgid ""
"The rpc request to the mds node, if found that the mds request timeout, then "
"need to retry, if multiple retries fail, then may have switched the main mds, "
"then need to switch the mds to continue to retry;"
msgstr ""
"向mds节点请求的rpc，如果发现mds请求超时，那么需要重试，如果多次重试失败，那么可"
"能切换了主mds，此时需要切换mds继续重试；"

#: ../../source/architecture/client-architecture.md:71
#: 637b9f43825a42c1893ace26e313a49e
msgid ""
"Request rpc to the node of the metaserver, if you receive a redirect reply or "
"request timeout, it may be due to the switch of the leader, then you need to "
"re-acquire the leader, and then retry the request;"
msgstr ""
"向metaserver的节点请求rpc，如果收到redirect的回复或者请求超时，则可能是因为切换"
"了leader，此时需要重新获取leader，然后重试请求；"

#: ../../source/architecture/client-architecture.md:73
#: 03120cffac7e4f9f8e4a6d3a46730fa8
msgid ""
"The above retry process also needs to ensure the idempotency of the request, "
"DingoFS Client for the idempotency of the request to ensure, mainly through "
"the following ways:"
msgstr ""
"上述重试过程还需要保证请求的幂等性，DingoFS Client对于请求的幂等性的保证，主要"
"通过以下几种方式："

#: ../../source/architecture/client-architecture.md:74
#: 833a2774a40c478bbc9eebb37339c8fc
msgid ""
"For requests of the delete class, if a NOT EXIST error is returned, then "
"DingoFS Client will directly assume that the deletion has been successful, and "
"thus idempotent execution is successful."
msgstr ""
"对于删除类的请求，如果返回NOT EXIST错误，那么DingoFS Client会直接认为已经删除成"
"功，从而幂等地执行成功。"

#: ../../source/architecture/client-architecture.md:75
#: 3d82ddd47e824e30b6c96dcaea997daf
msgid ""
"For requests to mds, such as Mount FS, which do not have high performance "
"requirements, the DingoFS Client first gets the current mount point via Get "
"FsInfo, and then goes to Mount FS. In this way, it is guaranteed that the "
"Mount FS request was not mounted before it was sent, and if it still returns "
"EXIST, then it is certain that the rpc retry request is a successful one. If "
"it still returns EXIST, then it can be sure that it is caused by the rpc retry "
"request, so the idempotent return execution is successful."
msgstr ""
"对于向mds请求的，如Mount FS等请求，这些请求对于性能要求不高，DingoFS Client首先"
"会通过Get FsInfo获取当前挂载点的情况，之后再去Mount FS。通过这种方式，保证"
"Mount FS请求发送前没有被挂载，如果仍然返回了EXIST，那么可以肯定是rpc重试请求造"
"成的，因此幂等的返回执行成功。"

#: ../../source/architecture/client-architecture.md:76
#: 10ac417d656b470bb1e16bc6b62780d4
msgid ""
"Some other requests, such as CreateDentry, etc., according to the uniqueness "
"of InodeId in the content of the CreateDentry request (the inodeId of the "
"request in the retry CreateDentry is the same, and the inodeId of the request "
"in the non-retry request must be different) to distinguish whether it is a "
"retry request or not, and thus idempotent return is successful, or return the "
"EXIST error."
msgstr ""
"其他一些请求，如CreateDentry等，则根据CreateDentry请求内容中InodeId唯一性（重试"
"的CreateDentry中请求的inodeId是一致的，非重试的请求InodeId一定不同）来区分是否"
"是重试的请求，从而幂等的返回成功，或者返回EXIST错误。"

#: ../../source/architecture/client-architecture.md:78
#: ac53e9a68f45450d97e08904eb43f2e3
msgid "6.Key design"
msgstr "6.关键设计"

#: ../../source/architecture/client-architecture.md:79
#: 755437517e2e42f7b636795225798c8c
msgid "Rename"
msgstr ""

#: ../../source/architecture/client-architecture.md:80
#: c80d0106072e4867a10402fac37b311e
msgid ""
"The rename interface of DingoFS borrows from leveldb and etcd(boltdb) to "
"ensure atomicity, and the design is shown below:"
msgstr ""
"DingoFS 的rename 接口，为了保证原子性，借鉴了 leveldb 与 etcd(boltdb) 中事务的"
"实现，设计如下图所示："

#: ../../source/architecture/client-architecture.md:82
#: 6607fc630dab435997fef0fe91e46d9b
msgid "![rename.png](../../images/rename.png)"
msgstr ""

#: ../../source/architecture/client-architecture.md:82
#: dc6b641ab63345358d660523e51ffdc8
msgid "rename.png"
msgstr ""

#: ../../source/architecture/client-architecture.md:84
#: 3c71cb2bf0464df9a97feb173347a192
msgid ""
"The rename mechanism is designed to add a txid field to all MDS copysets to "
"store the successful transaction ids of the current copyset (the transaction "
"ids are incremented in order, and one is added for each successful "
"transaction);"
msgstr ""
"rename机制设计在 MDS 所有 copyset 中增加一个 txid 字段，保存当前 copyset 已成功"
"的事务 id（该事务 id 顺序递增，事务每成功一次则加一）；"

#: ../../source/architecture/client-architecture.md:85
#: fd9be08980ae4221adfa259c417f285e
msgid ""
"At the beginning of each rename, add 1 (copyset_txid+1) to the txid "
"corresponding to the copyset where srcDentry, dstDentry are located to delete/"
"create/modify the dentry (in fact, it is the creation of a copy, no matter "
"delete/create/modify, it is to create a copy of the corresponding "
"copyset_txid+1 is key), the original dentry does not move, the original dentry "
"does not move. The original dentry remains intact, and set PendingTx to the "
"current transaction;"
msgstr ""
"每次 rename 开始时，将 srcDentry, dstDentry 所在 copyset 对应的 txid 分别加 1 "
"(copyset_txid+1) 去删除/创建/修改 dentry（其实就是创建副本，不管是删除/创建/更"
"改都是创建相应 copyset_txid+1 为 key 的副本，原始 dentry 不动），并设置 "
"PendingTx 为本次事务；"

#: ../../source/architecture/client-architecture.md:86
#: 4e62e53f26a74e36bf92f96396b12c9e
msgid ""
"If the previous step succeeds, submit the transaction, add 1 to the txid of "
"the copyset where srcDentry, dstDentry are located (this step is guaranteed by "
"the transaction of etcd), if the previous step fails or this step fails, since "
"the txid is unchanged, and the original version of the data is also there, or "
"to ensure the atomicity (in fact, a txid corresponds to a version of the data);"
msgstr ""
"如果上一步骤成功了，就提交事务，将 srcDentry, dstDentry 所在 copyset 的 txid 都"
"加 1（这一步是通过 etcd 的事务保证的），如果上一步或这一步失败，因为 txid 不"
"变，原始数据版本也在，还是保证原子性（其实就是一个 txid 对应一个版本的数据）；"

#: ../../source/architecture/client-architecture.md:87
#: 4f39bb2d24354f30a84cbd1f4bfc26db
msgid ""
"The next time you access the copyset, bring the latest txid (copyset_txid) of "
"the corresponding copyset, judge the PendingTx, if (copyset_txid >= "
"PendingTxId && rpc_request.key == PendingTxKey), the transaction corresponding "
"to PendingTx has been successful, if the transaction corresponding to "
"PendingTx happens to operate the requested dentry, return the copy dentry "
"corresponding to PendingTxKey + PendingTxId; otherwise, return the original "
"dentry; otherwise, return the original dentry. If the transaction "
"corresponding to PendingTx happens to operate on the requested dentry, the "
"copy of the dentry corresponding to PendingTxKey + PendingTxId is returned, "
"otherwise the original dentry is returned;"
msgstr ""
"下次访问的时候，带上对应 copyset 的最新 txid (copyset_txid)，判断 PendingTx，如"
"果 (copyset_txid >= PendingTxId && rpc_request.key == PendingTxKey)，则表明 "
"PendingTx 对应的事务是已经成功了的，并且 PendingTx 对应事务刚好操作的是请求的 "
"dentry，则返回 PendingTxKey + PendingTxId 对应的副本 dentry，否则返回原始 "
"dentry；"

#: ../../source/architecture/client-architecture.md:88
#: 068865ceb3af492aa1bf20269ee9beb2
msgid ""
"PendingTx and dentry copy are one-to-one correspondence, each copyset only "
"needs one PendingTx (i.e., at most one copy dentry will be kept in the whole "
"copyset);"
msgstr ""
"PendingTx 与 dentry 副本是一一对应的，每个 copyset 只需要一个 PendingTx（即整"
"个 copyset 中最多只会存留一个副本 dentry)；"

#: ../../source/architecture/client-architecture.md:90
#: df52aa30218e4adcab4cb259c82eb288
msgid ""
"DingoFS client's rename mechanism finally realizes the atomicity of the whole "
"Rename by committing the transaction to etcd atomically on the mds side."
msgstr ""
"DingoFS client的rename机制通过在mds端向etcd原子的提交事务的方式，最终实现了整个"
"Rename的原子性。"
